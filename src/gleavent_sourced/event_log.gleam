import gleam/dict
import gleam/dynamic.{type Dynamic}
import gleam/dynamic/decode
import gleam/int
import gleam/json
import gleam/list
import gleam/option.{None, Some}
import gleam/result
import gleam/string

import gleam/erlang/process
import gleam/time/timestamp.{type Timestamp}
import gleavent_sourced/event_filter.{type EventFilter}

import pog

/// Custom error type for query operations that can fail at database or mapping level
pub type QueryError {
  DatabaseError(pog.QueryError)
  JsonParseError(json.DecodeError)
  MappingError(String)
}

// Event type for reading events from the database
// sequence_number is auto-generated by PostgreSQL
pub type Event {
  Event(
    sequence_number: Int,
    occurred_at: Timestamp,
    event_type: String,
    payload: dynamic.Dynamic,
    metadata: dict.Dict(String, String),
  )
}

/// Result type for append operations with optimistic concurrency control
pub type AppendResult {
  AppendSuccess
  AppendConflict(conflict_count: Int)
}

pub fn connect(pool_name: process.Name(pog.Message)) -> pog.Connection {
  pog.named_connection(pool_name)
}

pub fn append_events(
  db: pog.Connection,
  events: List(event_type),
  event_converter: fn(event_type) -> #(String, json.Json),
  metadata: dict.Dict(String, String),
  conflict_filter: EventFilter,
  last_seen_sequence: Int,
) -> Result(AppendResult, pog.QueryError) {
  // Convert events to JSON array format
  let events_json_array =
    events
    |> json.array(fn(event) {
      let #(event_type, payload_json) = event_converter(event)
      json.object([
        #("type", json.string(event_type)),
        #("data", payload_json),
        #(
          "metadata",
          json.object(
            dict.to_list(metadata)
            |> list.map(fn(pair) { #(pair.0, json.string(pair.1)) }),
          ),
        ),
      ])
    })
    |> json.to_string

  // Generate dynamic SQL with conflict checking
  let sql_and_params = case conflict_filter {
    event_filter.EventFilter(filters) ->
      build_dynamic_insert_sql(filters, last_seen_sequence, events_json_array)
    event_filter.CustomSql(sql, params) ->
      build_custom_sql_insert_sql(
        sql,
        params,
        last_seen_sequence,
        events_json_array,
      )
  }

  let batch_query =
    pog.query(sql_and_params.sql)
    |> list.fold(sql_and_params.params, _, fn(query, param) {
      pog.parameter(query, param)
    })
    |> pog.returning(append_result_decoder())

  pog.execute(batch_query, on: db)
  |> result.map(fn(returned) {
    let assert [row] = returned.rows
    let #(status, conflict_count) = row
    case status {
      "success" -> AppendSuccess
      "conflict" -> AppendConflict(conflict_count: conflict_count)
      _ -> panic as "unexpected status from batch insert"
    }
  })
}

/// Query events with dynamic SQL generation for fact tagging
/// Returns events grouped by fact ID
pub fn query_events_with_tags(
  db: pog.Connection,
  filter: EventFilter,
  event_mapper: fn(String, Dynamic) -> Result(event_type, String),
) -> Result(#(dict.Dict(String, List(event_type)), Int), QueryError) {
  // Generate SQL based on filter type
  let sql_and_params = case filter {
    event_filter.EventFilter(filters) -> build_dynamic_query_sql(filters)
    event_filter.CustomSql(sql, params) ->
      SqlAndParams(sql: sql, params: params)
  }
  let select_query =
    pog.query(sql_and_params.sql)
    |> list.fold(sql_and_params.params, _, fn(query, param) {
      pog.parameter(query, param)
    })
    |> pog.returning(dynamic_query_decoder())

  case pog.execute(select_query, on: db) {
    Ok(returned) -> {
      let raw_rows = returned.rows

      // Get max sequence number (all rows have the same value)
      let max_sequence = case raw_rows {
        [] -> 0
        [first, ..] -> first.max_sequence_number
      }

      // Group events by fact ID and map them
      list.try_map(raw_rows, fn(row) {
        case json.parse(row.payload, decode.dynamic) {
          Ok(payload_dynamic) ->
            case event_mapper(row.event_type, payload_dynamic) {
              Ok(event) -> Ok(#(row.fact_id, event))
              Error(msg) -> Error(MappingError(msg))
            }
          Error(err) -> Error(JsonParseError(err))
        }
      })
      |> result.map(fn(events) {
        list.group(events, fn(pr) { pr.0 })
        |> dict.map_values(fn(_k, pairs) { list.map(pairs, fn(pr) { pr.1 }) })
      })
      |> result.map(fn(events_dict) { #(events_dict, max_sequence) })
    }
    Error(err) -> Error(DatabaseError(err))
  }
}

/// Result type for dynamic query results
type DynamicQueryResult {
  DynamicQueryResult(
    fact_id: String,
    sequence_number: Int,
    event_type: String,
    payload: String,
    metadata: String,
    max_sequence_number: Int,
  )
}

/// Helper type for dynamic SQL generation
type SqlAndParams {
  SqlAndParams(sql: String, params: List(pog.Value))
}

/// Group FilterConditions by their tag
fn group_conditions_by_tag(
  conditions: List(event_filter.FilterCondition),
) -> List(#(String, List(event_filter.FilterCondition))) {
  let indexed_conditions =
    list.index_map(conditions, fn(condition, index) {
      let tag = case condition.tag {
        Some(tag) -> tag
        None -> "condition" <> int.to_string(index)
      }
      #(tag, condition)
    })

  list.group(indexed_conditions, by: fn(pair) { pair.0 })
  |> dict.to_list()
  |> list.map(fn(group) {
    let #(tag, pairs) = group
    let conditions = list.map(pairs, fn(pair) { pair.1 })
    #(tag, conditions)
  })
}

/// Build a single CTE for a group of conditions with the same tag (using OR)
fn build_tag_group_cte(
  tag: String,
  conditions: List(event_filter.FilterCondition),
  start_param_index: Int,
  select_clause: String,
  extra_where: String,
) -> SqlAndParams {
  let cte_name = case tag {
    "" -> "untagged_events"
    _ -> "tag_" <> string.replace(tag, "-", "_") <> "_events"
  }

  let indexed_conditions =
    list.index_map(conditions, fn(condition, index) { #(condition, index) })

  let or_clauses =
    list.map(indexed_conditions, fn(pair) {
      let #(_condition, index) = pair
      let param_index_event_type = start_param_index + index * 2 + 1
      let param_index_payload = start_param_index + index * 2 + 2

      "("
      <> "e.event_type = $"
      <> int.to_string(param_index_event_type)
      <> " AND e.payload @> $"
      <> int.to_string(param_index_payload)
      <> "::jsonb"
      <> ")"
    })

  let where_clause = case or_clauses {
    [] -> "WHERE false"
    [single] -> "WHERE " <> single
    multiple -> "WHERE (" <> string.join(multiple, " OR ") <> ")"
  }

  let cte =
    cte_name
    <> " AS ("
    <> "  SELECT "
    <> select_clause
    <> "  FROM events e"
    <> "  "
    <> where_clause
    <> extra_where
    <> ")"

  let params =
    list.flatten(
      list.map(conditions, fn(condition) {
        [
          pog.text(condition.event_type),
          pog.text(json.to_string(condition.filter_expr)),
        ]
      }),
    )

  SqlAndParams(sql: cte, params: params)
}

/// Build UNION clause from tag groups
fn build_union_clause(
  tag_groups: List(#(String, List(event_filter.FilterCondition))),
) -> String {
  let cte_names =
    list.map(tag_groups, fn(group) {
      let #(tag, _) = group
      case tag {
        "" -> "untagged_events"
        _ -> "tag_" <> string.replace(tag, "-", "_") <> "_events"
      }
    })

  case cte_names {
    [] -> ""
    [single] -> single
    multiple -> string.join(multiple, " UNION SELECT * FROM ")
  }
}

/// Build dynamic SQL query with CTEs for each filter condition
fn build_dynamic_query_sql(
  conditions: List(event_filter.FilterCondition),
) -> SqlAndParams {
  case conditions {
    [] ->
      SqlAndParams(
        sql: "SELECT NULL as fact_id, sequence_number, event_type, payload, metadata, 0 as max_sequence_number FROM events WHERE false",
        params: [],
      )
    _ -> {
      // Group conditions by tag and build CTEs with correct parameter indexing
      let tag_groups = group_conditions_by_tag(conditions)

      let #(results, _) =
        list.fold(tag_groups, #([], 0), fn(acc, group) {
          let #(results_acc, param_index) = acc
          let #(tag, group_conditions) = group
          let fact_id = "'" <> tag <> "'"
          let select_clause =
            fact_id
            <> " as fact_id, e.sequence_number, e.event_type, e.payload, e.metadata"
          let result =
            build_tag_group_cte(
              tag,
              group_conditions,
              param_index,
              select_clause,
              "",
            )
          let next_param_index = param_index + list.length(group_conditions) * 2
          #([result, ..results_acc], next_param_index)
        })

      let results = list.reverse(results)
      let ctes = list.map(results, fn(result) { result.sql })
      let params = list.flatten(list.map(results, fn(result) { result.params }))

      let union_clause =
        "all_events AS ("
        <> "  SELECT * FROM "
        <> build_union_clause(tag_groups)
        <> ")"

      let final_sql =
        "WITH "
        <> string.join(ctes, ", ")
        <> ", "
        <> union_clause
        <> " SELECT e.fact_id, e.sequence_number, e.event_type, e.payload, e.metadata,"
        <> " MAX(e.sequence_number) OVER () as max_sequence_number"
        <> " FROM all_events e"
        <> " ORDER BY e.sequence_number"

      SqlAndParams(sql: final_sql, params: params)
    }
  }
}

/// Build dynamic SQL INSERT with conflict checking
fn build_dynamic_insert_sql(
  conditions: List(event_filter.FilterCondition),
  last_seen_sequence: Int,
  events_json_array: String,
) -> SqlAndParams {
  case conditions {
    [] ->
      // No conflict conditions, just insert directly
      SqlAndParams(
        sql: "WITH new_events_parsed AS (
          SELECT
            event_data ->> 'type' as event_type,
            event_data -> 'data' as event_data,
            event_data -> 'metadata' as metadata
          FROM jsonb_array_elements($1) AS event_data
        ),
        insert_result AS (
          INSERT INTO events (event_type, payload, metadata)
          SELECT event_type, event_data, metadata
          FROM new_events_parsed
          RETURNING sequence_number
        )
        SELECT 'success' as status, 0 as conflict_count
        FROM (SELECT 1) dummy
        WHERE EXISTS(SELECT 1 FROM insert_result)",
        params: [pog.text(events_json_array)],
      )
    _ -> {
      // Build CTEs for conflict checking
      let extra_where =
        "    AND e.sequence_number > " <> int.to_string(last_seen_sequence)
      let tag_groups = group_conditions_by_tag(conditions)

      let #(results, _) =
        list.fold(tag_groups, #([], 1), fn(acc, group) {
          let #(results_acc, param_index) = acc
          let #(tag, group_conditions) = group
          let result =
            build_tag_group_cte(
              tag,
              group_conditions,
              param_index,
              "e.sequence_number",
              extra_where,
            )
          let next_param_index = param_index + list.length(group_conditions) * 2
          #([result, ..results_acc], next_param_index)
        })

      let results = list.reverse(results)
      let ctes = list.map(results, fn(result) { result.sql })
      let conflict_params =
        list.flatten(list.map(results, fn(result) { result.params }))
      let conflict_union = build_union_clause(tag_groups)

      let final_sql =
        "WITH "
        <> string.join(ctes, ", ")
        <> ", conflict_check (conflict_count) AS ("
        <> "  SELECT COUNT(*) FROM ("
        <> "    SELECT sequence_number FROM "
        <> conflict_union
        <> "  ) conflicts"
        <> "), new_events_parsed AS ("
        <> "  SELECT"
        <> "    event_data ->> 'type' as event_type,"
        <> "    event_data -> 'data' as event_data,"
        <> "    event_data -> 'metadata' as metadata"
        <> "  FROM jsonb_array_elements($1) AS event_data"
        <> "), insert_result AS ("
        <> "  INSERT INTO events (event_type, payload, metadata)"
        <> "  SELECT event_type, event_data, metadata"
        <> "  FROM new_events_parsed"
        <> "  WHERE (SELECT conflict_count FROM conflict_check) = 0"
        <> "  RETURNING sequence_number"
        <> ")"
        <> "SELECT"
        <> "  CASE"
        <> "    WHEN EXISTS(SELECT 1 FROM insert_result) THEN 'success'"
        <> "    ELSE 'conflict'"
        <> "  END as status,"
        <> "  (SELECT conflict_count FROM conflict_check) as conflict_count"

      let all_params = [pog.text(events_json_array), ..conflict_params]
      SqlAndParams(sql: final_sql, params: all_params)
    }
  }
}

/// Build dynamic SQL INSERT with custom SQL for conflict checking
fn build_custom_sql_insert_sql(
  custom_sql: String,
  custom_params: List(pog.Value),
  last_seen_sequence: Int,
  events_json_array: String,
) -> SqlAndParams {
  // Calculate parameter numbers - custom params come first
  let custom_param_count = list.length(custom_params)
  let last_seq_param_num = custom_param_count + 1
  let events_array_param_num = custom_param_count + 2

  // Wrap the custom SQL to filter by sequence_number > last_seen_sequence
  let conflict_sql =
    "WITH custom_conflicts AS ("
    <> custom_sql
    <> ") SELECT sequence_number FROM custom_conflicts WHERE sequence_number > $"
    <> int.to_string(last_seq_param_num)

  let final_sql =
    "WITH conflict_check (conflict_count) AS ("
    <> "  SELECT COUNT(*) FROM ("
    <> conflict_sql
    <> "  ) conflicts"
    <> "), new_events_parsed AS ("
    <> "  SELECT"
    <> "    event_data ->> 'type' as event_type,"
    <> "    event_data -> 'data' as event_data,"
    <> "    event_data -> 'metadata' as metadata"
    <> "  FROM jsonb_array_elements($"
    <> int.to_string(events_array_param_num)
    <> ") AS event_data"
    <> "), insert_result AS ("
    <> "  INSERT INTO events (event_type, payload, metadata)"
    <> "  SELECT event_type, event_data, metadata"
    <> "  FROM new_events_parsed"
    <> "  WHERE (SELECT conflict_count FROM conflict_check) = 0"
    <> "  RETURNING sequence_number"
    <> ")"
    <> "SELECT"
    <> "  CASE"
    <> "    WHEN EXISTS(SELECT 1 FROM insert_result) THEN 'success'"
    <> "    ELSE 'conflict'"
    <> "  END as status,"
    <> "  (SELECT conflict_count FROM conflict_check) as conflict_count"

  let all_params =
    list.append(custom_params, [
      pog.int(last_seen_sequence),
      pog.text(events_json_array),
    ])
  SqlAndParams(sql: final_sql, params: all_params)
}

/// Decoder for append results
fn append_result_decoder() -> decode.Decoder(#(String, Int)) {
  use status <- decode.field(0, decode.string)
  use conflict_count <- decode.field(1, decode.int)
  decode.success(#(status, conflict_count))
}

/// Decoder for dynamic query results
fn dynamic_query_decoder() -> decode.Decoder(DynamicQueryResult) {
  use fact_id <- decode.field(0, decode.string)
  use sequence_number <- decode.field(1, decode.int)
  use event_type <- decode.field(2, decode.string)
  use payload <- decode.field(3, decode.string)
  use metadata <- decode.field(4, decode.string)
  use max_sequence_number <- decode.field(5, decode.int)
  decode.success(DynamicQueryResult(
    fact_id:,
    sequence_number:,
    event_type:,
    payload:,
    metadata:,
    max_sequence_number:,
  ))
}
